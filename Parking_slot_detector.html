<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Parking-slot tester 0.2</title>
  <style>
    html,body { margin:0;height:100%;overflow:hidden;background:#000; }
    video,canvas { position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover; }
    #log { position:absolute;bottom:0;left:0;width:100%;background:#000a;color:#0f0;
           font:14px/1.4 monospace;padding:4px;pointer-events:none;white-space:pre-wrap; }
  </style>
</head>
<body>
  <video id="cam" muted playsinline></video>
  <canvas id="hud"></canvas>
  <pre id="log"></pre>

<script type="module">
import * as tf from 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js';

/* ---------- helper ------------------------------------------------------ */
const log = (...m) => document.getElementById('log').textContent += m.join(' ')+'\n';

/* ---------- 1. start camera -------------------------------------------- */
async function startCamera(){
  try{
    const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}});
    cam.srcObject = stream;
    await cam.play();
    log('üé• camera stream OK');
  }catch(e){ log('‚ùå getUserMedia:', e.message); }
}
const cam = document.getElementById('cam');
await startCamera();

/* ---------- 2. WebXR feature probe (optional) --------------------------- */
let useXR = false, xrSession, xrRefSpace, xrHitSource;
if (navigator.xr){
  const isArCapable = await navigator.xr.isSessionSupported('immersive-ar');
  log('WebXR present  :', isArCapable);
  if (isArCapable){
    xrSession = await navigator.xr.requestSession('immersive-ar',{
      optionalFeatures:['hit-test','plane-detection','depth-sensing','dom-overlay'],
      domOverlay:{root:document.body}
    });
    xrRefSpace   = await xrSession.requestReferenceSpace('local');
    const feats  = xrSession.enabledFeatures.values();
    log('XR features   :', [...feats].join(', '));
    // Only ask for a hit-test source if the feature exists
    if (xrSession.enabledFeatures.has?.('hit-test')){
      xrHitSource = await xrSession.requestHitTestSource({space:xrRefSpace});
      log('hit-test ready');
    }
    useXR = true;
  }
}else{
  log('No navigator.xr (desktop / iOS <17.4)');
}

/* ---------- 3. canvas resize ------------------------------------------- */
const cvs = document.getElementById('hud');
const ctx = cvs.getContext('2d');
function resize(){ cvs.width = cam.videoWidth; cvs.height = cam.videoHeight; }
cam.addEventListener('loadedmetadata', resize); window.addEventListener('resize', resize);

/* ---------- 4. main loop (fallback vs XR) ------------------------------ */
function fallbackLoop(){ drawCamFrame(); requestAnimationFrame(fallbackLoop); }
function drawCamFrame(){
  if (!cam.videoWidth) return;          // camera not ready yet
  ctx.drawImage(cam,0,0,cvs.width,cvs.height);
  //  ‚Üë add your YOLO + measurement overlay here
}

if (useXR){
  xrSession.requestAnimationFrame(function onXR(t,frame){
    xrSession.requestAnimationFrame(onXR);
    drawCamFrame();                     // for now just reuse the same drawing
    // you can hit-test here using frame.getHitTestResults(xrHitSource)
  });
}else fallbackLoop();
</script>
</body>
</html>
