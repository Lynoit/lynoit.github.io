<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>4× USB Webcam Viewer (Master-Sync, mtime-based length)</title>
<style>
  body { margin:0; font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif; background:#111; color:#eee; display:flex; height:100vh; overflow:hidden; }
  #sidebar { width:260px; background:#1b1b1b; border-right:1px solid #333; display:flex; flex-direction:column; }
  #sessionList { flex:1; overflow-y:auto; padding:8px; }
  .session { padding:8px 10px; border-radius:6px; margin-bottom:4px; background:#222; cursor:pointer; }
  .session:hover { background:#2c2c2c; }
  .session.active { background:#2c7be5; color:#fff; }
  #main { flex:1; display:flex; flex-direction:column; overflow:hidden; }
  #toolbar { padding:8px 12px; border-bottom:1px solid #333; background:#141414; display:flex; align-items:center; gap:8px; }
  #videos { flex:1; display:grid; grid-template-columns:repeat(2,1fr); grid-template-rows:repeat(2,1fr); gap:6px; padding:6px; }
  video { width:100%; height:100%; object-fit:contain; background:#000; }
  .vwrap { position:relative; }
  .vwrap header { position:absolute; top:4px; left:4px; background:rgba(0,0,0,0.5); padding:2px 6px; border-radius:4px; font-size:12px; }
  .overlay { position:absolute; inset:0; pointer-events:none; }
  #timeline { width:100%; }
  #currentTime { width:70px; text-align:right; font-variant-numeric:tabular-nums; }
  #sessionName { font-variant-numeric:tabular-nums; }
  button { background:#2c7be5; border:none; color:#fff; padding:6px 10px; border-radius:6px; cursor:pointer; }
  button:hover { background:#3d8af0; }
  label { display:flex; align-items:center; gap:6px; }
  input[type="number"] { width:76px; }
</style>

<!-- Detection libs -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3/dist/coco-ssd.min.js"></script>
</head>
<body>
  <div id="sidebar">
    <div style="padding:8px;border-bottom:1px solid #333;">
      <button id="pickFolder">Open Folder</button>
    </div>
    <div id="sessionList"></div>
  </div>

  <div id="main">
    <div id="toolbar">
      <button id="playPause" disabled>▶️ Play</button>
      <input id="timeline" type="range" min="0" max="100" value="0" step="0.01" disabled />
      <span id="currentTime">00:00</span>
      <div style="flex:1"></div>

      <!-- Detection controls -->
      <label title="Run object detection on the Front camera">
        <input type="checkbox" id="detectToggle" checked />
        Detect Front Objects
      </label>
      <label title="Horizontal FOV of the Front camera (degrees)">
        FOV°
        <input type="number" id="fovInput" min="20" max="180" step="0.1" value="90" />
      </label>

      <span id="sessionName"></span>
    </div>

    <div id="videos">
      <div class="vwrap">
        <header>Front</header>
        <video id="vidFront" preload="metadata" muted></video>
        <canvas id="ovlFront" class="overlay"></canvas>
      </div>
      <div class="vwrap"><header>Back</header> <video id="vidBack"  preload="metadata" muted></video></div>
      <div class="vwrap"><header>Left</header> <video id="vidLeft"  preload="metadata" muted></video></div>
      <div class="vwrap"><header>Right</header><video id="vidRight" preload="metadata" muted></video></div>
    </div>
  </div>

<script>
(async () => {
  const pickBtn = document.getElementById('pickFolder');
  const sessionList = document.getElementById('sessionList');
  const playPause = document.getElementById('playPause');
  const timeline = document.getElementById('timeline');
  const currentTime = document.getElementById('currentTime');
  const sessionNameEl = document.getElementById('sessionName');
  const vids = {
    Front: document.getElementById('vidFront'),
    Back:  document.getElementById('vidBack'),
    Left:  document.getElementById('vidLeft'),
    Right: document.getElementById('vidRight')
  };

  // Detection globals
  const ovlFront = document.getElementById('ovlFront');
  const detectToggle = document.getElementById('detectToggle');
  const fovInput = document.getElementById('fovInput');

  const CLASS_HEIGHTS = {
    person: 1.70,
    car: 1.50,
    bus: 3.20,
    truck: 3.00,
    bicycle: 1.50,
    motorcycle: 1.40
  };
  const KEEP = new Set(Object.keys(CLASS_HEIGHTS));
  const DISPLAY_LABEL = { person: 'pedestrian' };

  let cocoModel = null;
  let detRunning = false;
  let cancelDetCb = null;
  let lastInferT = 0;
  const INFER_EVERY_MS = 120;

  // Offscreen canvas sized to the *draw area* (letterboxed region) for inference
  const inferCanvas = document.createElement('canvas');
  const inferCtx = inferCanvas.getContext('2d');

  let sessions = {};
  let currentSession = null;
  let baseDate = new Date(NaN);
  let master = null;
  let rVFCHandle = null;
  let playing = false;

  // Sync thresholds (seconds)
  const SOFT_SLEW_TH = 0.030;
  const HARD_JUMP_TH = 0.100;
  const MAX_SLEW = 0.03;

  // ---------- Utils ----------
  function fmtTime(sec){
    sec = Math.max(0,sec);
    const m=Math.floor(sec/60), s=Math.floor(sec%60);
    return `${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')}`;
  }
  function fmtHMSfromDate(dt){
    const h=dt.getHours(), m=dt.getMinutes(), s=dt.getSeconds();
    return `${String(h).padStart(2,'0')}:${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')}`;
  }
  function parseBaseDate(stamp){
    const m = stamp.match(/^(\d{4})(\d{2})(\d{2})_(\d{2})(\d{2})(\d{2})$/);
    if(!m) return new Date(NaN);
    const [_, Y, Mo, D, h, mi, s] = m;
    return new Date(+Y, +Mo-1, +D, +h, +mi, +s, 0);
  }
  const clamp = (v,min,max)=>Math.max(min,Math.min(max,v));
  const round1 = (x)=>Math.round(x*10)/10;

  async function pickFolder() {
    let files = [];
    if (window.showDirectoryPicker) {
      const dir = await window.showDirectoryPicker();
      for await (const entry of dir.values()) {
        if (entry.kind==='file' && entry.name.endsWith('.webm')) {
          files.push(await entry.getFile());
        }
      }
    } else {
      const input = document.createElement('input');
      input.type='file';
      input.multiple=true;
      input.accept='.webm';
      input.click();
      files = await new Promise(res=>{
        input.onchange=()=>res([...input.files]);
      });
    }
    parseSessions(files);
  }

  function parseSessions(files){
    sessions={};
    for(const f of files){
      const m = f.name.match(/^(\d{8}_\d{6})_(Front|Back|Left|Right)\.webm$/i);
      if(!m) continue;
      const [,stamp,pos] = m;
      sessions[stamp] ||= {};
      sessions[stamp][pos] = f;
    }
    renderSidebar();
  }

  function renderSidebar(){
    sessionList.innerHTML='';
    const stamps = Object.keys(sessions).sort().reverse();
    for(const stamp of stamps){
      const div=document.createElement('div');
      div.className='session';
      div.textContent=stamp;
      div.onclick=()=>loadSession(stamp,div);
      sessionList.appendChild(div);
    }
  }

  async function loadSession(stamp,elem){
    stopSyncLoop();
    stopDetectionLoop();
    playing = false;
    playPause.textContent='▶️ Play';
    playPause.dataset.state='paused';

    [...sessionList.children].forEach(c=>c.classList.remove('active'));
    elem.classList.add('active');
    currentSession=stamp;

    baseDate = parseBaseDate(stamp);
    sessionNameEl.textContent = fmtHMSfromDate(baseDate);

    playPause.disabled=false;
    timeline.disabled=false;

    master = null;
    for(const pos of ['Front','Back','Left','Right']){
      const v = vids[pos];
      const file = sessions[stamp][pos];
      if(file){
        v.src = URL.createObjectURL(file);
        v.play().catch(()=>{});
        v.pause();
        v.currentTime=0;
        if (!master) master = v;
      } else {
        v.removeAttribute('src');
      }
      v.playbackRate = 1.0;
    }

    await Promise.all(Object.values(vids).map(v=> new Promise(r=>{
      if (!v.src) return r();
      v.onloadedmetadata=()=>r();
      setTimeout(r,500);
    })));

    resizeOverlayToFront();

    const filesInSession = ['Front','Back','Left','Right']
      .map(pos => sessions[stamp][pos])
      .filter(Boolean);
    let elapsedByMtimeSec = 0;
    if (filesInSession.length) {
      const latestMs = Math.max(...filesInSession.map(f => f.lastModified || 0));
      const startMs  = baseDate.getTime();
      if (isFinite(latestMs) && isFinite(startMs) && latestMs > startMs) {
        elapsedByMtimeSec = Math.floor((latestMs - startMs) / 1000);
      }
    }
    const durations = Object.values(vids).map(v => (v.src ? (v.duration || 0) : 0));
    const maxDur = Math.max(...durations, 0);
    const totalSec = elapsedByMtimeSec > 0 ? elapsedByMtimeSec : maxDur;

    timeline.max = totalSec || 0;
    timeline.value=0;
    currentTime.textContent = fmtTime(0);
    sessionNameEl.textContent = fmtHMSfromDate(baseDate);
  }

  // playback control
  playPause.addEventListener('click', async ()=>{
    if(!currentSession || !master) return;
    const isPlaying = playPause.dataset.state==='playing';
    if(isPlaying){
      pauseAll();
      stopDetectionLoop();
    } else {
      playAll();
      if (detectToggle.checked) {
        await ensureModelLoaded();
        startDetectionLoop();
      }
    }
  });

  function playAll(){
    playPause.textContent='⏸ Pause';
    playPause.dataset.state='playing';
    playing = true;

    for (const v of Object.values(vids)) {
      if (!v.src) continue;
      v.play().catch(()=>{});
    }
    startSyncLoop();
  }

  function pauseAll(){
    playPause.textContent='▶️ Play';
    playPause.dataset.state='paused';
    playing = false;

    for (const v of Object.values(vids)) {
      if (!v.src) continue;
      v.pause();
      v.playbackRate = 1.0;
    }
    stopSyncLoop();
  }

  // detection toggle
  detectToggle.addEventListener('change', async ()=>{
    if (detectToggle.checked && playing) {
      await ensureModelLoaded();
      startDetectionLoop();
    } else {
      stopDetectionLoop(true);
    }
  });

  // timeline scrubbing
  timeline.addEventListener('input', ()=>{
    if(!master) return;
    const t=parseFloat(timeline.value);
    master.currentTime = t;
    for (const v of Object.values(vids)) {
      if (v !== master && v.src) v.currentTime = t;
    }
    currentTime.textContent = fmtTime(t);
    const nowDt = new Date(baseDate.getTime() + Math.floor(t)*1000);
    sessionNameEl.textContent = fmtHMSfromDate(nowDt);
    clearOverlay();
  });

  // master-driven sync loop
  function startSyncLoop(){
    if (!master) return;
    const followers = Object.values(vids).filter(v => v !== master && v.src);

    const loop = () => {
      const t = master.currentTime || 0;

      const tClamped = Math.min(t, parseFloat(timeline.max) || t);
      timeline.value = tClamped;
      currentTime.textContent = fmtTime(tClamped);
      const nowDt = new Date(baseDate.getTime() + Math.floor(tClamped)*1000);
      sessionNameEl.textContent = fmtHMSfromDate(nowDt);

      for (const v of followers) {
        const drift = (v.currentTime || 0) - t;
        const adrift = Math.abs(drift);

        if (adrift > HARD_JUMP_TH) {
          v.currentTime = t;
          v.playbackRate = 1.0;
        } else if (adrift > SOFT_SLEW_TH) {
          const sign = (drift > 0) ? -1 : 1;
          const adj = Math.min(MAX_SLEW, Math.max(-MAX_SLEW, sign * Math.min(MAX_SLEW, adrift * 0.5)));
          v.playbackRate = 1.0 + adj;
        } else {
          v.playbackRate = 1.0;
        }
      }

      if (playing && master.requestVideoFrameCallback) {
        rVFCHandle = master.requestVideoFrameCallback(() => loop());
      } else if (playing) {
        rVFCHandle = setTimeout(loop, 33);
      }
    };

    if (master.requestVideoFrameCallback) {
      rVFCHandle = master.requestVideoFrameCallback(() => loop());
    } else {
      rVFCHandle = setTimeout(loop, 33);
    }
  }

  function stopSyncLoop(){
    if (master && master.cancelVideoFrameCallback && rVFCHandle) {
      try { master.cancelVideoFrameCallback(rVFCHandle); } catch {}
    } else if (rVFCHandle) {
      clearTimeout(rVFCHandle);
    }
    rVFCHandle = null;
  }

  // ------- Detection helpers (letterbox mapping, overlay, distance) -------
  function resizeOverlayToFront(){
    const box = vids.Front.getBoundingClientRect();
    ovlFront.width  = Math.max(1, Math.round(box.width));
    ovlFront.height = Math.max(1, Math.round(box.height));
  }
  function clearOverlay(){
    const ctx = ovlFront.getContext('2d');
    ctx.clearRect(0,0,ovlFront.width, ovlFront.height);
  }
  window.addEventListener('resize', resizeOverlayToFront);

  async function ensureModelLoaded(){
    if (!cocoModel) {
      cocoModel = await cocoSsd.load({ base: 'lite_mobilenet_v2' });
    }
  }

  // Compute how the intrinsic video maps into the visible letterboxed area
  function computeLetterboxMapping(videoEl, canvasEl){
    const vw = Math.max(1, videoEl.videoWidth || 1);
    const vh = Math.max(1, videoEl.videoHeight || 1);
    const cw = Math.max(1, canvasEl.width  || 1);
    const ch = Math.max(1, canvasEl.height || 1);

    const videoAspect  = vw / vh;
    const canvasAspect = cw / ch;

    let drawW, drawH, padX, padY;
    if (videoAspect > canvasAspect) {
      // full width, centered vertically
      drawW = cw;
      drawH = cw / videoAspect;
      padX = 0;
      padY = (ch - drawH) / 2;
    } else {
      // full height, centered horizontally
      drawH = ch;
      drawW = ch * videoAspect;
      padY = 0;
      padX = (cw - drawW) / 2;
    }

    const scaleX = drawW / vw;
    const scaleY = drawH / vh;

    return { vw, vh, cw, ch, drawW, drawH, padX, padY, scaleX, scaleY };
  }

  // Distance estimation from bbox height (display pixels) + FOV
  function estimateDistanceMeters(bbox, label){
    const Hreal = CLASS_HEIGHTS[label];
    if (!Hreal) return null;
    const imgH = ovlFront.height;
    const imgW = ovlFront.width;
    const hPix = bbox[3];
    if (hPix <= 2) return null;

    const hFovDeg = parseFloat(fovInput.value) || 90;
    const hFov = hFovDeg * Math.PI/180;
    const vFov = 2 * Math.atan( Math.tan(hFov/2) * (imgH/imgW) );
    const fy = (imgH/2) / Math.tan(vFov/2);

    const Z = (Hreal * fy) / hPix;
    return clamp(Z, 0.1, 300);
  }

  function drawDetections(dets, map){
    const ctx = ovlFront.getContext('2d');
    clearOverlay();
    ctx.lineWidth = 2;
    ctx.font = '12px system-ui, Segoe UI, Roboto, Arial, sans-serif';

    for (const d of dets){
      const {bbox, class: label, score} = d;
      if (!KEEP.has(label)) continue;

      // bbox is in inferCanvas (draw area) coords; shift by padding only
      const x = map.padX + bbox[0];
      const y = map.padY + bbox[1];
      const w = bbox[2];
      const h = bbox[3];

      const dist = estimateDistanceMeters([x,y,w,h], label);
      const name = DISPLAY_LABEL[label] || label;          // person -> pedestrian
      const labelText = `${name} ${(score*100).toFixed(0)}%` + (dist ? ` • ${round1(dist)} m` : '');

      ctx.strokeStyle = 'rgba(72, 190, 255, 0.95)';
      ctx.strokeRect(x, y, w, h);

      const pad = 4;
      const metrics = ctx.measureText(labelText);
      const textH = 14;
      const textW = metrics.width + pad*2;
      const textX = Math.max(0, Math.min(ovlFront.width - textW, x));
      const textY = Math.max(0, y - (textH + 6));
      ctx.fillStyle = 'rgba(0,0,0,0.65)';
      ctx.fillRect(textX, textY, textW, textH + 4);
      ctx.fillStyle = '#eaf6ff';
      ctx.fillText(labelText, textX + pad, textY + textH - 2);
    }
  }

  // Detection loop using offscreen infer canvas sized to the visible draw area
  function startDetectionLoop(){
    if (detRunning) return;
    detRunning = true;

    const v = vids.Front;
    if (!v || !v.src || !cocoModel) return;

    const step = async () => {
      if (!detRunning || !playing || !detectToggle.checked) return;

      const now = performance.now();
      if (now - lastInferT >= INFER_EVERY_MS) {
        lastInferT = now;
        try {
          const map = computeLetterboxMapping(vids.Front, ovlFront);

          // Resize infer canvas to draw area
          const targetW = Math.max(1, Math.floor(map.drawW));
          const targetH = Math.max(1, Math.floor(map.drawH));
          if (inferCanvas.width !== targetW || inferCanvas.height !== targetH) {
            inferCanvas.width  = targetW;
            inferCanvas.height = targetH;
          }

          // Draw intrinsic video to draw area (no padding)
          inferCtx.drawImage(
            vids.Front,
            0, 0, vids.Front.videoWidth || 1, vids.Front.videoHeight || 1,
            0, 0, inferCanvas.width, inferCanvas.height
          );

          // Detect on the infer canvas
          const preds = await cocoModel.detect(inferCanvas, 20);

          // Draw boxes shifted by padding to overlay
          drawDetections(preds, map);
        } catch (e) {
          console.error('Detection error:', e);
        }
      }

      if (v.requestVideoFrameCallback) {
        cancelDetCb = v.requestVideoFrameCallback(() => step());
      } else {
        cancelDetCb = setTimeout(step, 33);
      }
    };

    if (v.requestVideoFrameCallback) {
      cancelDetCb = v.requestVideoFrameCallback(() => step());
    } else {
      cancelDetCb = setTimeout(step, 33);
    }
  }

  function stopDetectionLoop(clear=false){
    detRunning = false;
    const v = vids.Front;
    if (v && v.cancelVideoFrameCallback && cancelDetCb) {
      try { v.cancelVideoFrameCallback(cancelDetCb); } catch {}
    } else if (cancelDetCb) {
      clearTimeout(cancelDetCb);
    }
    cancelDetCb = null;
    if (clear) clearOverlay();
  }

  pickBtn.onclick = pickFolder;
})();
</script>
</body>
</html>
